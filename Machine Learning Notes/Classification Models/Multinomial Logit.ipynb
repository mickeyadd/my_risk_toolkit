{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66697510",
   "metadata": {},
   "source": [
    "# Multinomial and Ordinal Logistic Regression\n",
    "\n",
    "The notebook on Logistic Regression covered the case with two categories or **Binary Logistic Regression**  \n",
    "\n",
    "This notebook expands on cases where there are multiple categories and the response variable has multiple **nominal** or **ordinal** values.\n",
    "\n",
    "\n",
    "## Levels of Measurement (Scales of Data)\n",
    "\n",
    "In statistics and data science, variables can be classified into **four levels of measurement**, based on the properties they possess:\n",
    "\n",
    "| Level of Measurement | Description                                                   | Examples                            | Arithmetic Operations Allowed | \n",
    "|:--------------------|:--------------------------------------------------------------|:------------------------------------|:------------------------------|\n",
    "| **Nominal**           | Categories with **no order**; purely labels or names            | Gender, Colors, Product Type        | None                          | \n",
    "| **Ordinal**           | Categories with a **meaningful order**, but unknown or unequal spacing | Credit Rating, Satisfaction Level   | Comparison (\\(<, >\\))         | \n",
    "| **Interval**          | Ordered numeric values with **equal intervals**, but no true zero | Temperature (Â°C, Â°F), Dates         | +, âˆ’, comparison              | \n",
    "| **Ratio**             | Ordered numeric values with **equal intervals and a true zero** | Height, Weight, Age, Income         | +, âˆ’, Ã—, Ã·, comparison        |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe8a2e",
   "metadata": {},
   "source": [
    "### Categorical Models\n",
    "\n",
    "The focus of this notebook will be on the multi-class categorical models for **nominal** and **ordinal** measurements.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da5104",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression  \n",
    "\n",
    "Recall that in the binary case where there are only two categories $ y \\in \\{0, 1\\} $:\n",
    "\n",
    "$$\n",
    "P(y = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p)}}\n",
    "$$\n",
    "\n",
    "and the Log-likelihood:\n",
    "\n",
    "$$\n",
    "\\ell(\\beta) = \\sum_{i=1}^n \\left[ y_i \\ln(p_i) + (1 - y_i) \\ln(1 - p_i) \\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574db2ff",
   "metadata": {},
   "source": [
    "Suppose the response variable $Y$ takes values in the set of categories\n",
    "\n",
    "$$\n",
    "Y \\in \\{1, 2, \\ldots, K\\}\n",
    "$$\n",
    "\n",
    "For each category $j = 1, 2, \\ldots, K - 1$, we use a different parameter vector $\\boldsymbol{\\beta}^{(j)} \\in \\mathbb{R}^{p+1}$, and impose the log-odds $\\ln \\frac{\\pi_j}{\\pi_K}$ to be linear.    \n",
    "\n",
    "\n",
    "$\\ln \\frac{\\pi_j}{\\pi_K} = \\mathbf{x}^{\\top} \\beta^{(j)} = \\beta^{(j)}_0 + \\beta^{(j)}_1 x_1 + \\cdots + \\beta^{(j)}_p x_p$\n",
    "\n",
    "where \n",
    "\n",
    "$P(Y = j \\mid \\mathbf{x}) = \\pi_j = \\pi_K \\ e^{x^{\\top} \\beta^{(j)}} \\propto e^{x^{\\top} \\beta^{(j)}}$\n",
    "\n",
    "subject to the constraint $\\sum_{i=1}^K \\pi_i = 1$ which yields  \n",
    "\n",
    "$$\n",
    "\\pi_j = \\dfrac{e^{x^{\\top} \\beta^{(j)}}}{\\sum_{i = 1}^{K} e^{x^{\\top} \\beta^{(i)}}} \\ , \\quad j = 1, 2, \\dots, K - 1, K\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a3821",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression (Softmax)  \n",
    "\n",
    "For multiple outcomes $Y \\in \\{1, 2, \\dots, K\\} $:\n",
    "\n",
    "$$\n",
    "P(y = k \\mid X) = \\dfrac{e^{(\\beta_{k0} + \\beta_{k1} x_1 + \\dots + \\beta_{kp} x_p)}}{\\sum_{j=1}^K e^{(\\beta_{j0} + \\beta_{j1} x_1 + \\dots + \\beta_{jp} x_p)}}\n",
    "$$\n",
    "\n",
    "Log-likelihood:\n",
    "\n",
    "$$\n",
    "\\ell(\\beta) = \\sum_{i=1}^n \\sum_{k=1}^K I(y_i = k) \\ln P(y_i = k \\mid X_i)\n",
    "$$\n",
    "\n",
    "Where $I(y_i = k)$ is an indicator function equal to $1$ if observation $i$ belongs to class $k$, and $0$ otherwise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62a9f4",
   "metadata": {},
   "source": [
    "### Ordinal Logistic Regression\n",
    "\n",
    "Instead of modeling the probability of being in one category directly, it models the **cumulative probability** of being in category *j* or below:\n",
    "\n",
    "$$\n",
    "\\log \\left( \\frac{P(y \\leq j)}{P(y > j)} \\right) = \\theta_j - \\beta^\\top X\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\theta_j$ is a **threshold** specific to category *j*\n",
    "- $\\beta$ is the set of coefficients for predictors (same for all thresholds)\n",
    "- Assumes the **proportional odds assumption**: the effect of predictors is constant across the different cumulative logits\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367fa2f",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“Œ When to Use  \n",
    "\n",
    "âœ… Use **ordinal logistic regression** when:\n",
    "- The target variable has **ordered, discrete categories**\n",
    "- You want to maintain the order information\n",
    "- The proportional odds assumption holds (can be tested)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050d9a1",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Can You Do This in Python?\n",
    "\n",
    "Yes â€” though **scikit-learn doesnâ€™t have built-in ordinal logistic regression**.  \n",
    "You can use:\n",
    "- ðŸ“¦ `statsmodels.miscmodels.ordinal_model.OrdinalModel`\n",
    "- ðŸ“¦ `mord` package (`pip install mord`) â€” an efficient implementation of ordinal logistic regression models\n",
    "\n",
    "---\n",
    "\n",
    "âœ… *A great option for credit scoring, customer satisfaction levels, risk rating grades, or any scenario where the outcome has a clear order but the spacing between outcomes isnâ€™t strictly numeric.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add571b",
   "metadata": {},
   "source": [
    "\n",
    "### Pros and Cons  \n",
    "\n",
    "| Pros                                                                                      | Cons                                                                                      |\n",
    "|:------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------|\n",
    "| Simple to implement and interpret                                                     | Assumes linear relationship between predictors and log-odds                               |\n",
    "| Provides interpretable coefficients (as odds ratios)                                   | Sensitive to multicollinearity                                                            |\n",
    "| Fast to train, even on large datasets                                                 | Can underperform with complex, nonlinear relationships                                    |\n",
    "| Probabilistic predictions â€” gives class probabilities, not just labels                | Assumes independence of irrelevant alternatives (IIA) in the multinomial case             |\n",
    "| Supports regularization (Ridge/Lasso/ElasticNet)                                      | Performance can degrade if predictors have very different scales (scaling usually needed) |\n",
    "| Well-understood statistical properties and asymptotics                                | May not perform well with highly imbalanced datasets without adjustment                   |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963e182",
   "metadata": {},
   "source": [
    "### When to Use  \n",
    "\n",
    "âœ… Use **Binary Logistic Regression** when:\n",
    "- The outcome is **binary** (two classes)\n",
    "- You need **interpretable coefficients**\n",
    "- You care about **probabilities** for decision-making\n",
    "- The relationship between predictors and outcome is reasonably **linear in the log-odds**\n",
    "\n",
    "âœ… Use **Multinomial Logistic Regression** when:\n",
    "- The outcome has **more than two unordered categories**\n",
    "- The categories are **mutually exclusive**\n",
    "- You need to interpret how predictors influence the probability of choosing one class over others\n",
    "- Simpler tree-based models (like decision trees or random forests) arenâ€™t offering enough interpretability or are overfitting\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124c067",
   "metadata": {},
   "source": [
    "## Alternatives  \n",
    "\n",
    "If logistic regression performance or assumptions are limiting:\n",
    "- **Decision Trees / Random Forests / Gradient Boosting**\n",
    "- **Support Vector Machines (SVM)**\n",
    "- **Naive Bayes**\n",
    "- **Neural Networks (for highly nonlinear, high-dimensional data)**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
